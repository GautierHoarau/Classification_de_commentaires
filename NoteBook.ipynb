{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NoteBook de Gautier Hoarau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sommaire\n",
    "1. [Importations et Chargement des Donnees](#1-importations-et-chargement-des-donnees)\n",
    "2. [Pretraitement des Donnees](#2-pretraitement-des-donnees)\n",
    "3. [Tokenization et Vectorisation](#3-tokenization-et-vectorisation)\n",
    "4. [Construction du Modele](#4-construction-du-modele)\n",
    "5. [Entrainement et Evaluation](#5-entrainement-et-evaluation)\n",
    "6. [Pipeline de Classification](#6-pipeline-de-classification)\n",
    "7. [Exemple test](#7-exemple-test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importations et Chargement des Donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Télécharger les stopwords\n",
    "nltk.download('punkt')     # Tokenisation des mots\n",
    "nltk.download('stopwords') # Liste des mots vides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "data = pd.read_csv('/content/drive/MyDrive/data_classification_commentaires_toxiques/train.csv')\n",
    "data.head()\n",
    "\n",
    "# Liste des colonnes représentant les différentes catégories de toxicité\n",
    "toxic_columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "# Création d'une nouvelle colonne 'label' dans le DataFrame, qui prend la valeur maximale parmi les colonnes de toxicité pour chaque ligne\n",
    "# Cela permet de marquer un commentaire comme toxique si l'une des catégories de toxicité a la valeur la plus élevée: 1 si le commentaire est toxique, 0 sinon\n",
    "data['label'] = data[toxic_columns].max(axis=1)\n",
    "\n",
    "# Affichage des premières lignes du DataFrame avec les colonnes 'comment_text' et 'label' pour vérifier que les résultats sont correctement associés aux commentaires\n",
    "print(data[['comment_text', 'label']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pretraitement des Donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de la fonction de nettoyage du texte\n",
    "def clean_text(text):\n",
    "    # Conversion du texte en minuscules et suppression des ponctuations\n",
    "    text = text.lower()\n",
    "    text = re.sub(f'[{re.escape(string.punctuation)}]', '', text)\n",
    "    return text\n",
    "\n",
    "# Fonction pour supprimer les mots vides d'un texte\n",
    "def remove_stopwords(text):\n",
    "    tokens = word_tokenize(text)    # Découpe du texte en mots\n",
    "    stop_words = set(stopwords.words('english')) # Liste des mots vides\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]  # Filtrage des mots vides\n",
    "    return ' '.join(filtered_tokens) # Réassemble les mots restants\n",
    "\n",
    "# Appliquer le prétraitement\n",
    "data['cleaned_text'] = data['comment_text'].apply(clean_text).apply(remove_stopwords)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tokenization et Vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du nombre maximum de mots et de la longueur maximale des séquences\n",
    "max_words = 10000\n",
    "max_len = 100\n",
    "\n",
    "# Initialisation du Tokenizer\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "# Apprentissage du Tokenizer sur le texte nettoyé\n",
    "tokenizer.fit_on_texts(data['cleaned_text'])\n",
    "# Conversion des textes\n",
    "sequences = tokenizer.texts_to_sequences(data['cleaned_text'])\n",
    "# Application du padding pour uniformiser la longueur des séquences\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Construction du Modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du modèle simple de réseau de neurones avec Keras\n",
    "model = Sequential([\n",
    "    # Couche d'embedding pour transformer les indices des mots en vecteurs\n",
    "    Embedding(input_dim=max_words, output_dim=64, input_length=max_len),\n",
    "    # Couche LSTM avec 64 neurones\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    # Couche LSTM avec 32 neurones\n",
    "    LSTM(32),\n",
    "    # Couche dense avec 16 neurones et activation ReLU\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Entrainement et Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle avec les données\n",
    "X = padded_sequences\n",
    "y = np.array(data['label'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entraînement du modèle\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Boucle pour évaluer le modèle pour chaque type de toxicité\n",
    "for toxic_type in toxic_columns:\n",
    "    print(f\"Évaluation pour la catégorie : {toxic_type}\")\n",
    "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "    # Prédiction des résultats sur l'ensemble de test (binaire : 0 ou 1)\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "    # Affichage du rapport de classification pour chaque catégorie\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    # Affichage de la matrice de confusion pour évaluer les prédictions\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    # Séparation des évaluations de chaque catégorie\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Affichage des courbes de perte et de précision pour l'entraînement et la validation\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pipeline de Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de prétraitement du texte et de prédiction de la toxicité\n",
    "def preprocess_and_predict(text, tokenizer, model, max_len=100):\n",
    "    # Nettoyage du texte\n",
    "    text_cleaned = clean_text(text)\n",
    "    # Stopwords\n",
    "    text_cleaned = remove_stopwords(text_cleaned)\n",
    "    # Conversion du texte en séquence d'indices de mots\n",
    "    sequence = tokenizer.texts_to_sequences([text_cleaned])\n",
    "    # Vérifie si le texte est vide\n",
    "    if len(sequence[0]) == 0:\n",
    "        return \"Inconnu (aucun mot reconnu)\"\n",
    "    # Padding\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_len, padding='post', truncating='post')\n",
    "    # Prédiction\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    # Classification\n",
    "    prob = prediction[0][0]\n",
    "    classification = \"Toxique\" if prob > 0.5 else \"Non toxique\"\n",
    "    # Retourne le résultat : \"Toxique\" si la probabilité est supérieure à 0.5, sinon \"Non toxique\"\n",
    "    return f\"{classification} (Score : {prob:.2f})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Exemple test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de prédiction sur un commentaire\n",
    "exemple = \"Tu es stupide et méchant !\"\n",
    "# Prédiction du modèle final\n",
    "resultat = preprocess_and_predict(exemple, tokenizer, model)  \n",
    "print(f\"Le commentaire est : {resultat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exemple = \"Bonjour, comment vas-tu ?\"\n",
    "resultat = preprocess_and_predict(exemple, tokenizer, model)\n",
    "print(f\"Le commentaire est : {resultat}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
