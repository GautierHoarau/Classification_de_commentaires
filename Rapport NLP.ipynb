{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rapport : Classification de Commentaires\n",
    "\n",
    "## Table des Matières\n",
    "1. [Contexte et Presentation du Projet](#1-contexte-et-presentation-du-projet)\n",
    "2. [Jeu de Donnees et Pretraitement](#2-jeu-de-donnees-et-pretraitement)\n",
    "   - [Lecture du Jeu de Donnees](#21-lecture-du-jeu-de-donnees)\n",
    "   - [Creation d'un Label Binaire](#22-creation-dun-label-binaire)\n",
    "   - [Nettoyage des commentaires](#23-nettoyage-des-commentaires)\n",
    "   - [Suppression des Stopwords](#24-suppression-des-stopwords)\n",
    "   - [Tokenization et Padding des textes](#25-tokenization-et-padding-des-textes)\n",
    "3. [Approche Utilisee](#3-approche-utilisee)\n",
    "   - [Modele Simple](#31-modele-simple)\n",
    "   - [Modele Final avec LSTM](#32-modele-final-avec-lstm)\n",
    "4. [Entrainement du Modele](#4-entrainement-du-modele)\n",
    "5. [Evaluation du Modele](#5-evaluation-du-modele)\n",
    "6. [Ameliorations Possibles](#6-ameliorations-possibles)\n",
    "7. [Pipeline de Classification](#7-pipeline-de-classification)\n",
    "8. [Conclusion](#8-conclusion)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Contexte et Presentation du Projet\n",
    "\n",
    "Les entreprises proposant des plateformes interactives où les utilisateurs peuvent laisser des commentaires sont confrontées à un défi majeur : modérer les contenus publiés. En effet, elles peuvent être tenues responsables des propos toxiques ou injurieux laissés par leurs utilisateurs. L'objectif de ce projet est donc de développer un modèle capable d’analyser automatiquement des commentaires et de les classifier en différentes catégories afin de faciliter la modération et d’améliorer l’expérience utilisateur.\n",
    "\n",
    "La classification des commentaires est un problème du traitement automatique du langage naturel (**NLP**). Ce domaine de l’intelligence artificielle permet d’extraire du sens à partir de textes et de prendre des décisions automatisées en fonction du contexte. Dans ce projet, l'objectif est d’identifier les commentaires toxiques en se basant sur des caractéristiques linguistiques et syntaxiques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Jeu de Donnees et Pretraitement\n",
    "\n",
    "Le projet utilise le jeu de données du **Jigsaw Toxic Comment Classification Challenge**, qui contient des commentaires annotés selon leur nature toxique. Les classes possibles comprennent des catégories telles que :\n",
    "\n",
    "- **Toxic** : Commentaire général toxique\n",
    "- **Severe toxic** : Commentaire particulièrement agressif\n",
    "- **Obscene** : Contenu obscène\n",
    "- **Threat** : Contenu menaçant\n",
    "- **Insult** : Insulte directe\n",
    "- **Identity hate** : Discours haineux basé sur l’identité\n",
    "\n",
    "### **Importation**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Prétraitement des données**\n",
    "\n",
    "Avant d'entraîner un modèle de classification, il est essentiel de nettoyer et de transformer les données afin d’optimiser leur exploitation. \n",
    "Mais nous allons d'abords créer un label binaire indiquant si un commentaire est toxique (si l'une des colonnes de toxicité vaut 1).\n",
    "\n",
    "### 2.1 Lecture du Jeu de Donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "data = pd.read_csv('/content/drive/MyDrive/data_classification_commentaires_toxiques/train.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Creation d'un Label Binaire\n",
    "\n",
    "On considère qu'un commentaire est toxique si au moins l'une des colonnes de toxicité vaut 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des colonnes représentant les différentes catégories de toxicité\n",
    "toxic_columns = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "# Création d'une nouvelle colonne 'label' dans le DataFrame, qui prend la valeur maximale parmi les colonnes de toxicité pour chaque ligne\n",
    "# Cela permet de marquer un commentaire comme toxique si l'une des catégories de toxicité a la valeur la plus élevée (1)\n",
    "data['label'] = data[toxic_columns].max(axis=1)\n",
    "\n",
    "# Affichage des premières lignes du DataFrame avec les colonnes 'comment_text' et 'label' pour vérifier que les résultats sont correctement associés aux commentaires\n",
    "print(data[['comment_text', 'label']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Nettoyage des commentaires\n",
    "\n",
    "Suppression des caractères spéciaux, conversion en minuscules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exemple de nettoyage des commentaires  estce que ça fonctionne \n"
     ]
    }
   ],
   "source": [
    "# Définition de la fonction de nettoyage du texte\n",
    "def clean_text(text):\n",
    "    # Conversion du texte en minuscules et suppression des ponctuations\n",
    "    text = text.lower()\n",
    "    text = re.sub(f'[{re.escape(string.punctuation)}]', '', text)\n",
    "    return text\n",
    "\n",
    "# Application de la fonction 'clean_text'\n",
    "data['comment_clean'] = data['comment_text'].apply(clean_text)\n",
    "\n",
    "# Affichage\n",
    "print(data['comment_clean'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Suppression des Stopwords\n",
    "\n",
    "Utilisation de NLTK pour retirer les mots vides (stopwords)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')      # Tokenisation des mots\n",
    "nltk.download('stopwords')  # Liste des mots vides\n",
    "\n",
    "# Fonction pour supprimer les mots vides d'un texte\n",
    "def remove_stopwords(text):\n",
    "    tokens = word_tokenize(text)  # Découpe du texte en mots\n",
    "    stop_words = set(stopwords.words('french'))  # Liste des mots vides\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]  # Filtrage des mots vides\n",
    "    return ' '.join(filtered_tokens)  # Réassemble les mots restants\n",
    "\n",
    "# Application de la fonction\n",
    "data['comment_clean'] = data['comment_clean'].apply(remove_stopwords)\n",
    "\n",
    "# Affichage des premières lignes\n",
    "print(data['comment_clean'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Tokenization et Padding des textes\n",
    "\n",
    "Transformation des phrases en une liste de mots exploitables par le modèle puis applique un padding pour uniformiser leur longueur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du nombre maximum de mots et de la longueur maximale des séquences\n",
    "max_words = 10000\n",
    "max_len = 100\n",
    "\n",
    "# Initialisation du Tokenizer avec un nombre maximum de mots et un token pour les mots inconnus\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "# Apprentissage du Tokenizer sur le texte nettoyé\n",
    "tokenizer.fit_on_texts(data['comment_clean'])\n",
    "# Conversion des textes\n",
    "sequences = tokenizer.texts_to_sequences(data['comment_clean'])\n",
    "# Application du padding pour uniformiser la longueur des séquences\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Affichage\n",
    "print(\"Shape des données après padding :\", padded_sequences.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Approche Utilisee\n",
    "\n",
    "### 3.1 Modele Simple\n",
    "\n",
    "Dans un premier temps, un modèle de base a été entraîné pour évaluer la difficulté du problème. Celui-ci utilisait un simple réseau de neurones denses avec une couche d'**embedding**. Ce modèle initial permet de comprendre si les données sont linéairement séparables et d'établir une ligne de base pour la performance attendue.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du modèle simple de réseau de neurones avec Keras\n",
    "model_simple = Sequential([\n",
    "    # Couche d'embedding pour transformer les indices des mots en vecteurs\n",
    "    Embedding(input_dim=10000, output_dim=16, input_length=20),\n",
    "    # Aplatissement des vecteurs en une seule dimension (Vecteur 1D)\n",
    "    Flatten(),\n",
    "    # Couche dense avec 16 neurones et activation ReLU\n",
    "    Dense(16, activation='relu'),\n",
    "    # Couche de sortie avec un neurone et activation sigmoïde pour une classification binaire\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_simple.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_simple.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Modele Final\n",
    "\n",
    "Progressivement, nous avons amélioré le modèle en intégrant des techniques avancées du deep learning, notamment :\n",
    "\n",
    "- Une couche **Embedding** permettant de mieux représenter les mots en fonction de leur contexte.\n",
    "- Deux couches **LSTM (Long Short-Term Memory)** capables de capturer les relations entre les mots et de gérer la dépendance à long terme entre eux.\n",
    "- Des couches **Dropout** pour éviter l’overfitting et assurer une meilleure généralisation du modèle.\n",
    "- Une couche **Dense** avec activation **sigmoïde** pour produire une probabilité indiquant si un commentaire est toxique ou non."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du modèle de réseau de neurones avec LSTM pour la classification binaire\n",
    "model_final = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=64, input_length=20),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_final.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'utilisation des LSTM est particulièrement adaptée aux tâches de classification de texte, car elles permettent de mieux prendre en compte la structure et la signification des phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entrainement du modele\n",
    "\n",
    "Le modèle final a été entraîné sur **80%** des données et testé sur **20%**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle avec les données\n",
    "X = padded_sequences\n",
    "y = np.array(data['label'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "history = model_final.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation du modele\n",
    "\n",
    "Plusieurs métriques d’évaluation ont été utilisées :\n",
    "\n",
    "- **Accuracy** : Mesure la proportion de classifications correctes.\n",
    "- **F1-score** : Prend en compte la précision et le rappel, essentiel dans un contexte de données déséquilibrées.\n",
    "- **Matrice de confusion** : Analyse les faux positifs et faux négatifs pour mieux comprendre les erreurs du modèle.\n",
    "Exemple de code pour évaluer le modèle avec scikit-learn :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boucle pour évaluer le modèle pour chaque type de toxicité\n",
    "for toxic_type in toxic_columns:\n",
    "    print(f\"Évaluation pour la catégorie : {toxic_type}\")\n",
    "    loss, accuracy = model_final.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "    # Prédiction des résultats sur l'ensemble de test (binaire : 0 ou 1)\n",
    "    y_pred = (model_final.predict(X_test) > 0.5).astype(\"int32\")\n",
    "    # Affichage du rapport de classification pour chaque catégorie\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    # Affichage de la matrice de confusion pour évaluer les prédictions\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    # Séparation des évaluations de chaque catégorie\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats obtenus montrent une bonne capacité du modèle à détecter les commentaires toxiques tout en limitant les faux positifs. Toutefois, certaines erreurs persistent, notamment dans la différenciation entre certaines catégories proches, comme *insult* et *obscene*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ameliorations Possibles\n",
    "\n",
    "Plusieurs améliorations pourraient être apportées pour affiner la classification et améliorer la précision du modèle :\n",
    "\n",
    "- **Utilisation de modèles pré-entraînés** : L’intégration de modèles avancés comme **BERT** ou **GPT** pourrait permettre une meilleure compréhension du langage et améliorer la classification.\n",
    "- **Augmentation des données** : Générer des variations de commentaires existants pour enrichir l’apprentissage du modèle.\n",
    "- **Optimisation des hyperparamètres** : Ajuster les paramètres tels que la taille des embeddings, le nombre de neurones par couche, et le taux de dropout pour obtenir de meilleures performances.\n",
    "- **Filtrage plus avancé des données** : Supprimer les commentaires ambigus ou mal étiquetés pour améliorer la qualité des données d’entraînement.\n",
    "- **Entraînement multi-catégories** : Modifier l’architecture du modèle pour classer les commentaires dans plusieurs catégories en même temps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Pipeline de Classification\n",
    "\n",
    "Nous avons mis en place une pipeline permettant de classifier une phrase brute saisie par l'utilisateur.  \n",
    "Cette pipeline suit ces étapes :\n",
    "1. Nettoyage du texte (mise en minuscules, suppression de la ponctuation)\n",
    "2. Suppression des stopwords\n",
    "3. Tokenization et conversion en séquence numérique\n",
    "4. Application d'un padding\n",
    "5. Passage dans le modèle entraîné pour obtenir une prédiction\n",
    "\n",
    "### **Implementation de la Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de prétraitement du texte et de prédiction de la toxicité\n",
    "def preprocess_and_predict(text, tokenizer, model, max_len=100):\n",
    "    # Nettoyage du texte\n",
    "    text_cleaned = clean_text(text)\n",
    "    # Stopwords\n",
    "    text_cleaned = remove_stopwords(text_cleaned)\n",
    "    # Conversion du texte en séquence d'indices de mots\n",
    "    sequence = tokenizer.texts_to_sequences([text_cleaned])\n",
    "    # Padding\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_len, padding='post', truncating='post')\n",
    "    # Prédiction\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    # Retourne le résultat : \"Toxique\" si la probabilité est supérieure à 0.5, sinon \"Non toxique\"\n",
    "    return \"Toxique\" if prediction > 0.5 else \"Non toxique\"\n",
    "\n",
    "# Exemple de prédiction sur un commentaire\n",
    "exemple = \"Je te déteste, tu es horrible !\"\n",
    "# Prédiction du modèle\n",
    "resultat = preprocess_and_predict(exemple, tokenizer, model_final)  \n",
    "print(f\"Le commentaire est : {resultat}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "Ce projet m'a permis de développer une solution efficace pour détecter automatiquement les commentaires toxiques sur une plateforme. L’utilisation des **LSTM** et du **deep learning** a montré des résultats prometteurs, bien qu’il reste encore des marges d’amélioration. \n",
    "\n",
    "L’approche développée ici pourrait être étendue à d’autres domaines nécessitant une modération automatisée du contenu, tels que :\n",
    "\n",
    "- Les réseaux sociaux\n",
    "- Les forums en ligne\n",
    "- Les plateformes de e-commerce\n",
    "\n",
    "L’implémentation de solutions plus avancées, intégrant des modèles de NLP pré-entraînés, pourrait permettre d’optimiser davantage la détection des propos toxiques et d’améliorer la sûreté des plateformes en ligne."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
